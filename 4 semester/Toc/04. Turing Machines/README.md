Turing Machines:

- [Introduction](#01-introduction)
- [Definition of Turing Machine TM as language Acceptors and Transducers](#02-definition-of-turing-machine-tm-as-language-acceptors-and-transducers)
- [Computable Languages and functions, Universal TM & Other modification](#03-computable-languages-and-functions-universal-tm--other-modification)
- [Multiple Tracks Turing Machine](#04-multiple-tracks-turing-machine)
- [Hierarchy of Formal Languages](#05-hierarchy-of-formal-languages)
  - [Recursive & Recursively Enumerable Languages](#a-recursive--recursively-enumerable-languages)
  - [Properties of RL and REL](#b-properties-of-rl-and-rel)
  - [Introduction of Context Sensitive Grammars and Languages](#c-introduction-of-context-sensitive-grammars-and-languages)
  - [The Chomsky Hierarchy](#d-the-chomsky-hierarchy)
- [Read More](#06-read-more)






 

## 01. Introduction


Turing Machine was invented by Alan Turing in 1936 and it is used to accept Recursive Enumerable Languages (generated by Type-0 Grammar). 

Turing machines are a fundamental concept in the theory of computation and play an important role in the field of computer science. They were first described by the mathematician and computer scientist Alan Turing in 1936 and provide a mathematical model of a simple abstract computer.

In the context of automata theory and the theory of computation, Turing machines are used to study the properties of algorithms and to determine what problems can and cannot be solved by computers. They provide a way to model the behavior of algorithms and to analyze their computational complexity, which is the amount of time and memory they require to solve a problem.

A Turing machine is a finite automaton that can read, write, and erase symbols on an infinitely long tape. The tape is divided into squares, and each square contains a symbol. The Turing machine can only read one symbol at a time, and it uses a set of rules (the transition function) to determine its next action based on the current state and the symbol it is reading.

The Turing machine’s behavior is determined by a finite state machine, which consists of a finite set of states, a transition function that defines the actions to be taken based on the current state and the symbol being read, and a set of start and accept states. The Turing machine begins in the start state and performs the actions specified by the transition function until it reaches an accept or reject state. If it reaches an accept state, the computation is considered successful; if it reaches a reject state, the computation is considered unsuccessful.

Turing machines are an important tool for studying the limits of computation and for understanding the foundations of computer science. They provide a simple yet powerful model of computation that has been widely used in research and has had a profound impact on our understanding of algorithms and computation.

A turing machine consists of a tape of infinite length on which read and writes operation can be performed. The tape consists of infinite cells on which each cell either contains input symbol or a special symbol called blank. It also consists of a head pointer which points to cell currently being read and it can move in both directions.



<p align="center">
  <img src="https://github.com/user-attachments/assets/efaac922-61b1-4b8e-ba30-021ff4e349ca " alt="Turing Machine" width="600" height="200">
</p>


 
A TM is expressed as a 7-tuple (Q, T, B, ?, ?, q0, F) where: 
 

- Q is a finite set of states
- T is the tape alphabet (symbols which can be written on Tape)
- B is blank symbol (every cell is filled with B except input alphabet initially)
- ? is the input alphabet (symbols which are part of input alphabet)
- ? is a transition function which maps Q × T ? Q × T × {L,R}. Depending on its present state and present tape alphabet (pointed by head pointer), it will move to new state, change the tape symbol (may or may not) and move head pointer to either left or right.
- q0 is the initial state
- F is the set of final states. If any state of F is reached, input string is accepted.

Let us construct a turing machine for L={0^n1^n|n>=1} 
 

- Q = {q0,q1,q2,q3} where q0 is initial state.
- T = {0,1,X,Y,B} where B represents blank.
- ? = {0,1}
- F = {q3}
Transition function ? is given in Table 1 as: 

<p align="center">
  <img src="https://github.com/user-attachments/assets/384197c3-f394-4ba8-b268-e1c469120109" alt="Turing Machine" width="900" height="200">
</p>





- [read more about Turing Machine](https://www.geeksforgeeks.org/turing-machine-in-toc/)




## 02. Definition of Turing Machine TM as language Acceptors and Transducers

# Definition of Turing Machine (TM) as Language Acceptors and Transducers

## Definition of Turing Machine (TM)

### Overview of Turing Machines

A Turing Machine (TM) is a theoretical computational model introduced by Alan Turing in 1936. It is used to formalize the concept of computation and to understand the limits of what can be computed. A Turing Machine manipulates symbols on a strip of tape according to a set of rules.

### Components of a Turing Machine

- **Tape**: An infinitely long strip divided into cells, each containing a symbol from a finite alphabet.
- **Head**: A read/write head that scans the tape, capable of reading and writing symbols and moving left or right.
- **State Register**: Stores the current state of the Turing Machine, which is one of a finite number of states.
- **Transition Function**: A set of rules that determines the machine's actions based on the current state and the symbol being read.

### Types of Turing Machines

- **Deterministic Turing Machine (DTM)**: Each state and symbol pair has exactly one action.
- **Non-Deterministic Turing Machine (NDTM)**: Each state and symbol pair can have multiple possible actions.

## Turing Machines as Language Acceptors

 

### Language Acceptance

A Turing Machine acts as a language acceptor by accepting or rejecting strings of symbols based on the transition function.

#### Recognizable Languages

A language \( L \) is recognizable by a Turing Machine if there exists a Turing Machine \( M \) such that for any string \( w \) in \( L \), \( M \) enters the accept state.

 
### Examples of Turing Machines as Language Acceptors

- **Palindrome Recognition**: A Turing Machine can be designed to accept strings that are palindromes.
- **Binary Addition Verification**: A Turing Machine can be designed to accept strings representing valid sums of binary numbers.

## Turing Machines as Transducers

### Formal Definition

A Turing Machine can act as a transducer by transforming input strings into output strings. This is often represented by having multiple tapes (input and output tapes).

### Transduction Process

#### Input and Output Tapes

A Turing Machine with an input tape and an output tape can read from the input tape and write to the output tape, performing a transformation.

 

### Examples of Turing Machines as Transducers

- **Binary to Decimal Conversion**: A Turing Machine can convert a binary number on the input tape to its decimal equivalent on the output tape.
- **String Reversal**: A Turing Machine can reverse a string from the input tape and write the reversed string on the output tape.

## Comparative Analysis

### Differences between Acceptors and Transducers

- **Acceptors**: Turing Machines that determine membership in a language by accepting or rejecting strings.
- **Transducers**: Turing Machines that transform input strings into output strings.

### Applications and Use Cases

- **Language Acceptors**: Used in formal language theory, compiler design, and language recognition.
- **Transducers**: Used in data processing, function computation, and various transformations.

## Historical Context and Significance

### Development of the Turing Machine Concept

Alan Turing introduced the concept of the Turing Machine in his 1936 paper "On Computable Numbers, with an Application to the Entscheidungsproblem." This work laid the foundation for theoretical computer science.

### Impact on Computer Science and Computation Theory

Turing Machines have profoundly influenced the development of algorithms, complexity theory, and the understanding of the limits of computation. They remain a fundamental concept in computer science education and research.



- ![read more about Language accepted by Turing machine](4-semester/Toc/04.-Turing-Machines/01.-Language-accepted-by-Turing-machine.pdf)


- ![read more about Language accepted by Turing machine](https://github.com/musharraf-33-cyber-security/2-year-notes/blob/main/4%20semester/Toc/04.%20Turing%20Machines/01.%20Language%20accepted%20by%20Turing%20machine.pdf)
 













# 03. Computable Languages and functions, Universal TM & Other modification



## Computable Languages and Functions, Universal Turing Machine & Other Modifications

## Computable Languages and Functions

### Computable Languages

**Definition**:
A language \( L \) is considered **computable** if there exists a Turing Machine (TM) that can decide membership for any string \( w \). In other words, a language is computable if there is a TM that halts and correctly accepts or rejects each string in the language.

**Characteristics**:
- **Decidability**: For a language to be computable, there must be an algorithmic process that will always terminate and provide an answer about membership.
- **Examples**:
  - **Finite Languages**: Languages with a finite number of strings are computable because a TM can simply list all strings and check membership.
  - **Regular Languages**: Languages that can be described by regular expressions or finite automata are computable.
  - **Context-Free Languages**: Languages that can be generated by context-free grammars or parsed by pushdown automata are computable.

### Computable Functions

**Definition**:
A function \( f \) is considered **computable** if there exists a Turing Machine that, for any given input \( x \), will compute the value \( f(x) \) in a finite amount of time. 

**Characteristics**:
- **Total Function**: A function is computable if it produces an output for every input within a finite amount of time.
- **Examples**:
  - **Addition**: Given two integers, a TM can simulate the process of addition by carrying digits.
  - **Multiplication**: A TM can compute the product of two numbers through repeated addition.
  - **Factorial**: A TM can compute the factorial of a number by iterative multiplication.

### Examples of Computable Functions

1. **Addition**:
   - **Function**: \( f(a, b) = a + b \)
   - **TM Process**: The TM simulates the process of addition by counting the number of steps required to combine two numbers.

2. **Multiplication**:
   - **Function**: \( f(a, b) = a \times b \)
   - **TM Process**: The TM repeatedly adds \( a \) to itself \( b \) times or uses more advanced multiplication algorithms.

3. **Subtraction**:
   - **Function**: \( f(a, b) = a - b \)
   - **TM Process**: The TM performs subtraction by decrementing \( a \) \( b \) times, handling borrowing if necessary.

4. **Division**:
   - **Function**: \( f(a, b) = \frac{a}{b} \)
   - **TM Process**: The TM divides \( a \) by \( b \) through iterative subtraction and keeping track of remainders.

5. **Power Function**:
   - **Function**: \( f(x, n) = x^n \)
   - **TM Process**: The TM computes \( x \) raised to the power of \( n \) through repeated multiplication.

## Universal Turing Machine

### Definition

A **Universal Turing Machine (UTM)** is a special type of Turing Machine that can simulate the behavior of any other Turing Machine. The UTM is capable of executing any algorithm that can be described by a TM, given the description of the TM and its input.

### Functionality

- **Input Format**: A UTM receives as input a description of another TM \( M \) and an input string \( w \) for \( M \). The input is usually encoded in a way that includes the description of the TM \( M \) and the input \( w \) on the tape.
- **Simulation Process**: The UTM simulates the computation of \( M \) on \( w \) by:
  1. Decoding the description of \( M \).
  2. Setting up its own tape to simulate \( M \)’s tape.
  3. Simulating each step of \( M \)’s computation until \( M \) halts.
- **Output**: The UTM produces the same result that \( M \) would produce on the input \( w \).

### Importance

- **Universality**: The concept of a UTM demonstrates that a single machine can perform any computation that can be described algorithmically, reinforcing the notion of computational universality.
- **Foundation of Computability**: The UTM is foundational in theoretical computer science, showing that any computational problem solvable by a TM can be solved by a UTM.

## Other Modifications of Turing Machines

### Multi-Tape Turing Machines

**Definition**:
A Multi-Tape Turing Machine has multiple tapes, each with its own tape head. This extension allows the machine to perform more complex operations more efficiently.

**Characteristics**:
- **Efficiency**: Multi-tape TMs can often solve problems more efficiently by using one tape for input, another for output, and others for intermediate calculations.
- **Example**: A multi-tape TM can perform string copying or reversing operations more efficiently than a single-tape TM.

### Non-Deterministic Turing Machines

**Definition**:
A Non-Deterministic Turing Machine (NDTM) is a theoretical machine that can make multiple transitions from a given state. It can explore multiple computation paths simultaneously.

**Characteristics**:
- **Parallel Exploration**: NDTMs explore many possible paths in parallel, effectively "guessing" the correct path to a solution.
- **Complexity**: They are used to define complexity classes such as NP (Nondeterministic Polynomial time).

**Example**:
- **Language Acceptance**: An NDTM can accept a language by non-deterministically choosing the correct path that leads to an accepting state.

### Other Variants and Their Uses

**Multi-Dimensional Turing Machines**:
- **Definition**: These machines extend the tape to multiple dimensions (e.g., 2D or 3D grids).
- **Usage**: Useful for modeling computations that naturally occur in multidimensional spaces.

**Probabilistic Turing Machines**:
- **Definition**: Incorporate randomness into their computation. They make probabilistic choices at each step.
- **Usage**: Useful for algorithms where randomization can improve performance or solve problems more efficiently than deterministic methods.

**Quantum Turing Machines**:
- **Definition**: Based on principles of quantum mechanics, using quantum bits (qubits) and quantum operations.
- **Usage**: Used to explore quantum computation and develop quantum algorithms that can solve certain problems more efficiently than classical algorithms.

These modifications extend the classical Turing Machine model to address various computational and theoretical problems, providing a richer understanding of computation and complexity.



- ![read more about Computable Languages and functions, Universal TM & Other modification](https://github.com/musharraf-33-cyber-security/2-year-notes/blob/main/4%20semester/Toc/04.%20Turing%20Machines/Language%20accepted%20by%20Turing%20machine.pdf)












# 04. Multiple Tracks Turing Machine


## Multi-Tape Turing Machines

## Introduction

A **Multi-Tape Turing Machine** (MTTM) is an extension of the classical Turing Machine (TM) model that uses multiple tapes instead of a single tape. Each tape has its own tape head, and these heads can move independently of each other. The concept of multi-tape Turing Machines is used to study the efficiency and complexity of computational processes and to simplify certain algorithms.

## Definition

A Multi-Tape Turing Machine consists of:
- **Multiple Tapes**: Each tape is an infinite sequence of cells, similar to the single tape in a classical Turing Machine. The tapes are generally assumed to be bidirectional, allowing movement to the left or right.
- **Multiple Tape Heads**: Each tape head reads from and writes to its respective tape. The tape heads can move independently and simultaneously.
- **A Finite Set of States**: The machine operates based on a finite set of states and transition rules.
- **A Transition Function**: The transition function specifies the state changes, the symbols to be written on each tape, and the direction in which each tape head should move.

## Configuration

A configuration of a Multi-Tape Turing Machine at any given time consists of:
- The current state of the machine.
- The content of each tape, where each tape can have different content.
- The position of each tape head on its respective tape.

## Operation

1. **Reading and Writing**: The machine reads the symbols under each tape head and performs operations based on the transition function. It can write symbols on each tape, updating the content of the tapes.
2. **Head Movement**: Each tape head moves independently according to the transition rules. The machine can move each head to the left, right, or keep it stationary.
3. **State Transition**: The machine changes its state based on the symbols read and the transition function. The transition function dictates the next state and the actions to be taken (i.e., what to write on each tape and the direction of head movements).

## Example

Let’s illustrate a Multi-Tape Turing Machine with a simple example of copying a string:

**Problem**: Copy the string `aba` from Tape 1 to Tape 2.

**Initial Configuration**:
- **Tape 1**: `aba` (head at the first `a`)
- **Tape 2**: (empty)

**Steps**:

1. **Read**: Read `a` on Tape 1, write `a` on Tape 2, and move both heads right.
2. **Read**: Read `b` on Tape 1, write `b` on Tape 2, and move both heads right.
3. **Read**: Read `a` on Tape 1, write `a` on Tape 2, and move both heads right.
4. **End**: Tape 1 has reached the end of the input, and Tape 2 now contains `aba`.

**Final Configuration**:
- **Tape 1**: `aba` (head at the end of the string)
- **Tape 2**: `aba` (head at the end of the copied string)

## Advantages

1. **Efficiency**: Multi-Tape Turing Machines can often perform certain computations more efficiently than single-tape Turing Machines. For example, copying a string or performing parallel operations can be more straightforward with multiple tapes.
2. **Simplicity**: Some algorithms are simpler to describe and implement using multi-tape machines, as they can reduce the need for complex simulations required in single-tape machines.

## Theoretical Implications

1. **Equivalence**: Despite their practical advantages, Multi-Tape Turing Machines are not fundamentally more powerful than single-tape Turing Machines. Any computation performed by a Multi-Tape Turing Machine can be simulated by a single-tape Turing Machine, although potentially less efficiently.
2. **Complexity**: Multi-Tape Turing Machines provide insights into the efficiency of algorithms and help in understanding the computational complexity of problems.

## Example Transition Function

Here’s an example of a transition function for a simple Multi-Tape Turing Machine:

1. **State**: \( q_0 \)
   - **Tape 1**: Reads `a`, writes `a`, moves right.
   - **Tape 2**: Writes `a`, moves right.
   - **Next State**: \( q_1 \)

2. **State**: \( q_1 \)
   - **Tape 1**: Reads `b`, writes `b`, moves right.
   - **Tape 2**: Writes `b`, moves right.
   - **Next State**: \( q_2 \)

3. **State**: \( q_2 \)
   - **Tape 1**: Reads `a`, writes `a`, moves right.
   - **Tape 2**: Writes `a`, moves right.
   - **Next State**: \( q_3 \)

4. **State**: \( q_3 \)
   - **Tape 1**: Reads blank, halts.
   - **Tape 2**: (No further action needed)
   - **Next State**: \( q_{halt} \)

## Summary

Multi-Tape Turing Machines extend the classical Turing Machine model with multiple tapes and heads, allowing for more efficient and simpler algorithm implementations. While they offer practical advantages in computation, they are theoretically equivalent to single-tape Turing Machines in terms of computational power. Understanding multi-tape Turing Machines helps in analyzing algorithmic efficiency and complexity in theoretical computer science.












# 05. Hierarchy of Formal Languages
## Hierarchy of Formal Languages

The hierarchy of formal languages classifies languages based on their complexity and the computational power needed to recognize or generate them. The hierarchy is often represented as a series of language classes, each nested within a broader class. Here’s a detailed breakdown:

## 1. **Regular Languages**

### Definition

**Regular Languages** are the simplest type of formal languages. They can be recognized by finite automata and described by regular expressions.

### Characteristics

- **Recognition**: Can be recognized by Deterministic Finite Automata (DFA), Non-Deterministic Finite Automata (NFA), or Regular Expressions.
- **Closure Properties**: Closed under union, intersection, concatenation, and Kleene star (repetition).
- **Examples**: 
  - The language of all strings over the alphabet \(\{a, b\}\) that do not contain the substring "ab".
  - The set of all strings with an even number of `a`s.

### Generative Mechanism

Regular languages can be generated by regular grammars.

## 2. **Context-Free Languages**

### Definition

**Context-Free Languages** are more complex than regular languages and can be generated by Context-Free Grammars (CFG). They are recognized by pushdown automata.

### Characteristics

- **Recognition**: Can be recognized by Pushdown Automata (PDA).
- **Closure Properties**: Closed under union, concatenation, and Kleene star. Not closed under intersection and complement.
- **Examples**:
  - The language of balanced parentheses (e.g., `((()))`).
  - The language of palindromes over an alphabet \(\{a, b\}\).

### Generative Mechanism

Context-Free Languages can be generated by context-free grammars.

## 3. **Context-Sensitive Languages**

### Definition

**Context-Sensitive Languages** are more powerful than context-free languages and can be generated by Context-Sensitive Grammars (CSG). They are recognized by Linear Bounded Automata (LBA), which are Turing Machines with tape space bounded by the input size.

### Characteristics

- **Recognition**: Can be recognized by Linear Bounded Automata (LBA).
- **Closure Properties**: Closed under union, intersection, concatenation, and Kleene star.
- **Examples**:
  - The language \(\{a^n b^n c^n \mid n \geq 1\}\), where the number of `a`s, `b`s, and `c`s are equal.

### Generative Mechanism

Context-Sensitive Languages can be generated by context-sensitive grammars.

## 4. **Recursively Enumerable Languages**

### Definition

**Recursively Enumerable Languages** are the most general class of languages. They can be recognized by a Turing Machine but are not necessarily decidable. 

### Characteristics

- **Recognition**: Can be recognized by Turing Machines.
- **Closure Properties**: Closed under union, concatenation, and intersection. Not closed under complement.
- **Examples**:
  - The set of all Turing Machine descriptions and inputs for which the Turing Machine halts.

### Generative Mechanism

Recursively Enumerable Languages can be generated by unrestricted grammars.

## 5. **Recursive Languages**

### Definition

**Recursive Languages** are a subset of recursively enumerable languages. They are languages for which a Turing Machine halts on every input, providing an answer whether the input belongs to the language or not.

### Characteristics

- **Recognition**: Can be recognized by Turing Machines that always halt.
- **Closure Properties**: Closed under union, intersection, concatenation, complement, and Kleene star.
- **Examples**:
  - The language of all valid programs that halt.

### Generative Mechanism

Recursive Languages can be generated by type-0 grammars that are restricted to guarantee termination.

## Hierarchical Relationships

- **Regular Languages** are a subset of **Context-Free Languages**.
- **Context-Free Languages** are a subset of **Context-Sensitive Languages**.
- **Context-Sensitive Languages** are a subset of **Recursively Enumerable Languages**.
- **Recursive Languages** are a subset of **Recursively Enumerable Languages**.

The hierarchy is often depicted in a nested fashion, where each class of languages is included in the broader class above it. This hierarchy helps in understanding the complexity and capabilities of different computational models and languages.

## Summary

The hierarchy of formal languages provides a framework for understanding different classes of languages based on their generative power and computational complexity. Each level in the hierarchy represents a more complex class of languages that includes the class below it.






## (A) Recursive & Recursively Enumerable Languages

## Recursive and Recursively Enumerable Languages

## Recursive Languages

### Definition

**Recursive Languages** are a subset of **Recursively Enumerable Languages**. A language \( L \) is recursive if there exists a Turing Machine (TM) that will always halt and correctly decide whether any given string \( w \) belongs to \( L \) or not.

### Characteristics

- **Decidability**: For a recursive language, the Turing Machine halts on every input, providing a definitive yes or no answer.
- **Closure Properties**:
  - **Union**: If \( L_1 \) and \( L_2 \) are recursive, then \( L_1 \cup L_2 \) is recursive.
  - **Intersection**: If \( L_1 \) and \( L_2 \) are recursive, then \( L_1 \cap L_2 \) is recursive.
  - **Complement**: If \( L \) is recursive, then its complement \( \overline{L} \) is recursive.
  - **Concatenation**: If \( L_1 \) and \( L_2 \) are recursive, then \( L_1 \cdot L_2 \) is recursive.
  - **Kleene Star**: If \( L \) is recursive, then \( L^* \) is recursive.
- **Recognition**: Can be recognized by a Turing Machine that always halts.
- **Examples**:
  - The set of all valid mathematical proofs.
  - The language of all syntactically correct programs in a particular programming language that halt.

### Example

Consider a Turing Machine that decides the language \( L = \{w \mid w \text{ is a valid mathematical proof of a theorem}\} \). This language is recursive because there exists a Turing Machine that can verify the validity of proofs and will always halt after providing the correct answer.

## Recursively Enumerable Languages

### Definition

**Recursively Enumerable Languages** are a more general class of languages than recursive languages. A language \( L \) is recursively enumerable if there exists a Turing Machine that will accept any string \( w \) in \( L \) and either halt or run forever if \( w \) is not in \( L \). Essentially, these languages can be recognized by a Turing Machine but not necessarily decided.

### Characteristics

- **Recognizability**: For a recursively enumerable language, the Turing Machine will halt and accept if the string belongs to the language, but may not halt if the string does not belong.
- **Closure Properties**:
  - **Union**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cup L_2 \) is recursively enumerable.
  - **Intersection**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cap L_2 \) is recursively enumerable.
  - **Concatenation**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cdot L_2 \) is recursively enumerable.
  - **Kleene Star**: If \( L \) is recursively enumerable, then \( L^* \) is recursively enumerable.
  - **Complement**: The complement of a recursively enumerable language is not necessarily recursively enumerable.
- **Examples**:
  - The set of all Turing Machines that halt on a given input.
  - The language of all valid proofs in a formal system, where the system's completeness is not guaranteed.

### Example

Consider the language \( L = \{w \mid w \text{ is a description of a Turing Machine that halts on some input}\} \). This language is recursively enumerable because there is a Turing Machine that can simulate the described Turing Machine and accept if it halts, but the simulating Turing Machine might run forever if the described machine does not halt.

## Relationship Between Recursive and Recursively Enumerable Languages

- **Inclusion**: Every recursive language is recursively enumerable, but not every recursively enumerable language is recursive.
- **Decidability**: Recursive languages are decidable, meaning there is a Turing Machine that will always halt and decide membership. Recursively enumerable languages are only semi-decidable, meaning a Turing Machine may not halt if the string is not in the language.
- **Complement**: The complement of a recursive language is also recursive. However, the complement of a recursively enumerable language may not be recursively enumerable.

## Summary

- **Recursive Languages**: Decidable, with a Turing Machine that always halts and gives an answer.
- **Recursively Enumerable Languages**: Recognizable, with a Turing Machine that accepts strings in the language but might not halt for strings not in the language.

Understanding the distinctions and relationships between these classes of languages helps in analyzing problems related to computability and the limits of algorithmic processing.









## (B) Properties of RL and REL
    

## Regular Languages (RL)

### Definition

**Regular Languages** are the simplest class of formal languages. They can be recognized by finite automata and described using regular expressions. They are a subset of Context-Free Languages.

### Properties

1. **Closure Properties**:
   - **Union**: If \( L_1 \) and \( L_2 \) are regular, then \( L_1 \cup L_2 \) is regular.
   - **Intersection**: If \( L_1 \) and \( L_2 \) are regular, then \( L_1 \cap L_2 \) is regular.
   - **Complement**: If \( L \) is regular, then its complement \( \overline{L} \) is regular.
   - **Concatenation**: If \( L_1 \) and \( L_2 \) are regular, then \( L_1 \cdot L_2 \) is regular.
   - **Kleene Star**: If \( L \) is regular, then \( L^* \) (zero or more repetitions of \( L \)) is regular.
   
2. **Decidability**:
   - Regular languages are decidable. There exists a deterministic finite automaton (DFA) or regular expression that can decide membership in the language.

3. **Representations**:
   - **Finite Automata**: Can be represented by Deterministic Finite Automata (DFA) or Non-Deterministic Finite Automata (NFA).
   - **Regular Expressions**: Provide a concise way to describe regular languages.
   - **Regular Grammars**: Can be represented by right-linear or left-linear grammars.

4. **Equivalence**:
   - Every regular language can be expressed as a regular expression, and every regular expression defines a regular language.

5. **Decision Problems**:
   - **Membership**: Decidable in linear time using DFA.
   - **Emptiness**: Decidable in linear time.
   - **Finiteness**: Decidable in linear time.
   - **Equivalence**: Decidable in polynomial time.

### Examples

- The language consisting of all strings with an even number of `a`s: \( L = \{ w \mid w \text{ contains an even number of } a \text{s} \} \).
- The language of all strings over the alphabet \(\{0, 1\}\) that contain the substring `101`.

## Recursively Enumerable Languages (REL)

### Definition

**Recursively Enumerable Languages** are a broader class of languages than regular languages. They are languages for which a Turing Machine can recognize membership but may not always halt if the string is not in the language.

### Properties

1. **Closure Properties**:
   - **Union**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cup L_2 \) is recursively enumerable.
   - **Intersection**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cap L_2 \) is recursively enumerable.
   - **Concatenation**: If \( L_1 \) and \( L_2 \) are recursively enumerable, then \( L_1 \cdot L_2 \) is recursively enumerable.
   - **Kleene Star**: If \( L \) is recursively enumerable, then \( L^* \) is recursively enumerable.
   - **Complement**: The complement of a recursively enumerable language is not necessarily recursively enumerable.

2. **Decidability**:
   - Recursively enumerable languages are not necessarily decidable. Membership can be semi-decidable, meaning that a Turing Machine will halt and accept if the string is in the language, but it may run forever if the string is not in the language.

3. **Recognition**:
   - Recognizable by a Turing Machine. A Turing Machine can accept strings in the language but may not halt for strings not in the language.

4. **Equivalence**:
   - A language is recursively enumerable if there exists a Turing Machine that accepts it. Not all recursively enumerable languages are decidable.

5. **Decision Problems**:
   - **Membership**: Semi-decidable; the Turing Machine will halt and accept for strings in the language but may not halt for strings not in the language.
   - **Emptiness**: Undecidable in general (i.e., determining if a recursively enumerable language is empty is not always possible).
   - **Finiteness**: Undecidable in general (i.e., determining if a recursively enumerable language is finite is not always possible).
   - **Equivalence**: Undecidable in general (i.e., determining if two recursively enumerable languages are equivalent is not always possible).

### Examples

- The set of all Turing Machine descriptions that halt on some input.
- The language of all valid proofs in a formal system where completeness is not guaranteed.

## Summary

- **Regular Languages (RL)**: Are the simplest class, closed under a wide range of operations, decidable, and representable by finite automata or regular expressions.
- **Recursively Enumerable Languages (REL)**: Are more general, recognized by Turing Machines, and not necessarily decidable. They have broader closure properties but do not have closure under complementation.

Understanding these properties helps in analyzing the computational complexity and decidability of different language classes and the capabilities of various computational models.





## (C) Introduction of Context Sensitive Grammars and Languages

## Introduction to Context-Sensitive Grammars and Languages

## Context-Sensitive Grammars (CSG)

### Definition

**Context-Sensitive Grammars** (CSGs) are a type of formal grammar that generate **Context-Sensitive Languages** (CSLs). They are more powerful than Context-Free Grammars (CFGs) and are capable of expressing languages that cannot be described by CFGs. A context-sensitive grammar is defined by a 4-tuple \( G = (N, \Sigma, P, S) \), where:

- **N**: A finite set of non-terminal symbols.
- **\(\Sigma\)**: A finite set of terminal symbols.
- **P**: A finite set of production rules of the form \( \alpha \rightarrow \beta \), where \( \alpha \) and \( \beta \) are strings of non-terminals and terminals, and \( |\alpha| \leq |\beta| \). The length of the right-hand side (\(\beta\)) is at least as long as the left-hand side (\(\alpha\)).
- **S**: A start symbol, which is a special non-terminal from \( N \).

### Characteristics

1. **Production Rules**:
   - The rules are context-sensitive, meaning that the substitution of non-terminals depends on the surrounding symbols. This allows the grammar to handle languages with dependencies that are more complex than those manageable by context-free grammars.
   - Production rules must satisfy \( |\alpha| \leq |\beta| \), ensuring that the length of the string produced does not decrease.

2. **Generative Power**:
   - Context-sensitive grammars can generate languages that are not context-free. They are strictly more powerful than context-free grammars but less powerful than unrestricted grammars (type-0 grammars).

3. **Computational Model**:
   - Context-sensitive languages can be recognized by Linear Bounded Automata (LBA), which are Turing Machines with space bounded by the size of the input.

### Example

Consider the context-sensitive language \( L = \{ a^n b^n c^n \mid n \geq 1 \} \), which consists of strings with an equal number of `a`s, `b`s, and `c`s. This language can be generated by the following context-sensitive grammar:

1. \( S \rightarrow aSBC \)
2. \( aB \rightarrow Ba \)
3. \( bC \rightarrow Cb \)
4. \( aB \rightarrow Ab \)
5. \( bC \rightarrow bC \)
6. \( AC \rightarrow CA \)
7. \( aA \rightarrow Aa \)
8. \( A \rightarrow \epsilon \)

## Context-Sensitive Languages (CSL)

### Definition

**Context-Sensitive Languages** are languages that can be generated by context-sensitive grammars. They are recognized by Linear Bounded Automata (LBA), which operate within space limits proportional to the input size.

### Characteristics

1. **Recognition**:
   - Can be recognized by a Linear Bounded Automaton, which is a Turing Machine with tape space linearly bounded by the size of the input.

2. **Closure Properties**:
   - **Union**: The union of two context-sensitive languages is context-sensitive.
   - **Intersection**: The intersection of two context-sensitive languages is context-sensitive.
   - **Concatenation**: The concatenation of two context-sensitive languages is context-sensitive.
   - **Kleene Star**: The Kleene star of a context-sensitive language is context-sensitive.
   - **Complement**: Context-sensitive languages are not necessarily closed under complementation.

3. **Decidability**:
   - Membership testing for context-sensitive languages is decidable because LBAs can decide membership in a context-sensitive language.

4. **Examples**:
   - The language \( \{ a^n b^n c^n \mid n \geq 1 \} \), which requires an equal number of `a`s, `b`s, and `c`s.
   - The language of strings where each substring `a` is followed by a corresponding number of `b`s and `c`s, and `b`s are followed by corresponding `c`s.

## Summary

- **Context-Sensitive Grammars (CSG)**: A type of formal grammar that generates context-sensitive languages. They use production rules that allow non-terminals to be replaced in a context-sensitive manner, ensuring that the length of the string produced does not decrease.
- **Context-Sensitive Languages (CSL)**: Languages generated by context-sensitive grammars, recognized by Linear Bounded Automata. They are more complex than context-free languages but less complex than languages recognized by unrestricted grammars.

Understanding context-sensitive grammars and languages provides insights into the hierarchy of formal languages and the limits of computational models.





# The Chomsky Hierarchy

## (D) The Chomsky Hierarchy


## Introduction

The Chomsky Hierarchy is a classification of formal languages based on their generative power. It was proposed by Noam Chomsky in 1956. The hierarchy consists of four levels, each corresponding to a different type of formal grammar and automaton. These levels are, in order of increasing computational power: **Regular Languages**, **Context-Free Languages**, **Context-Sensitive Languages**, and **Recursively Enumerable Languages**.

## Levels of the Chomsky Hierarchy

### Type 3: Regular Languages

#### Definition

**Regular Languages** are the simplest class in the Chomsky Hierarchy. They can be described by regular expressions and recognized by finite automata.

#### Characteristics

- **Grammars**: Regular grammars, which include right-linear and left-linear grammars.
- **Automata**: Recognized by Deterministic Finite Automata (DFA) and Non-Deterministic Finite Automata (NFA).
- **Closure Properties**: Closed under union, intersection, complement, concatenation, and Kleene star.
- **Decidability**: Membership, emptiness, finiteness, and equivalence are all decidable.

#### Example

- The set of all strings over \(\{a, b\}\) that contain an even number of `a`s.

### Type 2: Context-Free Languages

#### Definition

**Context-Free Languages** (CFLs) are more powerful than regular languages. They are described by context-free grammars (CFGs).

#### Characteristics

- **Grammars**: Context-Free Grammars, where production rules are of the form \(A \rightarrow \alpha\) (A is a single non-terminal, and \(\alpha\) is a string of terminals and non-terminals).
- **Automata**: Recognized by Pushdown Automata (PDA).
- **Closure Properties**: Closed under union, concatenation, and Kleene star, but not under intersection and complement.
- **Decidability**: Membership is decidable (using the CYK algorithm or Earley's algorithm). Emptiness and finiteness are decidable. Equivalence is undecidable.

#### Example

- The set of all strings of balanced parentheses.

### Type 1: Context-Sensitive Languages

#### Definition

**Context-Sensitive Languages** (CSLs) are more powerful than context-free languages. They are described by context-sensitive grammars (CSGs).

#### Characteristics

- **Grammars**: Context-Sensitive Grammars, where production rules are of the form \(\alpha A \beta \rightarrow \alpha \gamma \beta\) (the length of \(\gamma\) is at least the length of A).
- **Automata**: Recognized by Linear Bounded Automata (LBA).
- **Closure Properties**: Closed under union, intersection, concatenation, and Kleene star. Not necessarily closed under complement.
- **Decidability**: Membership is decidable. Emptiness, finiteness, and equivalence are undecidable in general.

#### Example

- The set of all strings of the form \(a^n b^n c^n\) (equal numbers of `a`s, `b`s, and `c`s).

### Type 0: Recursively Enumerable Languages

#### Definition

**Recursively Enumerable Languages** (RELs) are the most powerful class in the Chomsky Hierarchy. They can be described by unrestricted grammars.

#### Characteristics

- **Grammars**: Unrestricted Grammars, where production rules are of the form \(\alpha \rightarrow \beta\) (with no restrictions on \(\alpha\) and \(\beta\)).
- **Automata**: Recognized by Turing Machines.
- **Closure Properties**: Closed under union, intersection, concatenation, and Kleene star. Not necessarily closed under complement.
- **Decidability**: Membership is semi-decidable. Emptiness, finiteness, and equivalence are undecidable in general.

#### Example

- The set of all Turing Machine descriptions that halt on a given input.

## Summary

The Chomsky Hierarchy organizes formal languages into four levels based on their complexity and the computational power required to recognize them. Understanding this hierarchy helps in the study of computational theory and the limits of different computational models.

1. **Type 3: Regular Languages**
   - Recognized by Finite Automata
   - Simplest and most restricted class
2. **Type 2: Context-Free Languages**
   - Recognized by Pushdown Automata
   - Includes languages that require a stack for recognition
3. **Type 1: Context-Sensitive Languages**
   - Recognized by Linear Bounded Automata
   - Includes languages that require more context for recognition
4. **Type 0: Recursively Enumerable Languages**
   - Recognized by Turing Machines
   - Most powerful and least restricted class

Each level in the hierarchy strictly contains the previous level, illustrating the increasing power and complexity of the grammars and automata.








## 06. Read More

- To know more about TOC , refer to this article ![Turing Machines notes](https://drive.google.com/file/d/1M3nUYI3XqOiXk_gOorKVlVIu-mGOZ69B/view)
- To know more about TOC , refer to this article ![TOC notes](https://hamrocsit.com/semester/fourth/toc/)
